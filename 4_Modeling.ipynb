{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9425af-4709-4c31-8cf5-f9db6a75f5eb",
   "metadata": {},
   "source": [
    "# 1. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0b3efc-6edf-48e0-8435-1ef9f0047ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DRT57226\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils import resample\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5376ed23-f26e-4ec2-ab89-e42eab5f35b3",
   "metadata": {},
   "source": [
    "# 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffaa7b4b-4de8-4857-b8ef-64be55acac2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>talk stone cold classic genre feels fresh thri...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>group youngsters discover taking part small ri...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>danny michael philippou truly made something s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched talk early part regals mystery monday ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>premise initially drew although different simi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews sentiment\n",
       "0  talk stone cold classic genre feels fresh thri...  Positive\n",
       "1  group youngsters discover taking part small ri...  Positive\n",
       "2  danny michael philippou truly made something s...  Positive\n",
       "3  watched talk early part regals mystery monday ...  Positive\n",
       "4  premise initially drew although different simi...  Positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('Data/model_reviews.csv')\n",
    "\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009aa017-75fa-4cfa-b5bd-a26914fa1094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    7665\n",
       "Negative    5772\n",
       "Neutral     1043\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b7084-ad5f-48f6-b44b-838b7dc3061f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Balancing classes and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117dd0df-ae01-441c-8464-0fa76a175701",
   "metadata": {},
   "source": [
    "**Resample explanations:** \n",
    "- replace: If True, upsampling will be done with replacement, meaning that the same instances can be sampled multiple times. This is commonly used in upsampling to balance the classes.\n",
    "\n",
    "- n_samples: The total number of samples after resampling. In the context of balancing classes, you usually want to set n_samples to the number of samples from the majority class, so that the minority class is increased to reach this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36e43ae-c746-4f87-af60-bdfd8282630f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class balancing\n",
    "df_positive = df_reviews[df_reviews['sentiment'] == 'Positive']\n",
    "df_negative = df_reviews[df_reviews['sentiment'] == 'Negative']\n",
    "df_neutral = df_reviews[df_reviews['sentiment'] == 'Neutral']\n",
    "\n",
    "# Upsample das classes 'Negative' e 'Neutral' to balance\n",
    "df_negative_upsampled = resample(df_negative, replace=True, n_samples=len(df_positive), random_state=42)\n",
    "df_neutral_upsampled = resample(df_neutral, replace=True, n_samples=len(df_positive), random_state=42)\n",
    "\n",
    "# Combine balanced df\n",
    "df_balanced = pd.concat([df_positive, df_negative_upsampled, df_neutral_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89620445-97e9-4267-9a88-6c6c85f5f85a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Naïve-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ec0ed9-981a-4c4d-aca7-5aa1781686a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "X = df_balanced['reviews']\n",
    "y = df_balanced['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a905c0-2c1e-414d-8056-055027c3619a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    7665\n",
       "Negative    7665\n",
       "Neutral     7665\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a502b4-96f3-453f-923d-ec6dce14dfc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1. Vectorization\n",
    "\n",
    "Enables a text convertion so it can be represented as numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93603f15-5d51-43a1-acf4-12a5096631e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93d530-510a-4f96-9d3a-10c7e52b6430",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 Spliting for training and test\n",
    "\n",
    "- Diving the data in train (80%) and test (20%) to follow the pareto principle \n",
    "- Traning a multinomial NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed29133-ff0c-4fd1-a8eb-dc65ca35e116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divisão dos dados em conjuntos de treinamento e teste (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criação e treinamento do modelo Naive Bayes Multinomial\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9248de98-f741-495b-87c5-d9d4c72e4ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4599.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.shape[0] * 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5329b31-b6a9-400d-949f-dfcbe27b719b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ccdbff-2036-4b24-aba9-29cc21292806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.81\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.79      0.80      1530\n",
      "     Neutral       0.88      0.87      0.87      1540\n",
      "    Positive       0.76      0.78      0.77      1529\n",
      "\n",
      "    accuracy                           0.81      4599\n",
      "   macro avg       0.81      0.81      0.81      4599\n",
      "weighted avg       0.81      0.81      0.81      4599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Realização de previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliação do desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy:.2f}')\n",
    "\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7dd82f-1cf3-4ca3-9a1d-a632907efcb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Confusion Matrix Function\n",
    "# def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "#     cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "#     plt.title('Confusion matrix')\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('Real')\n",
    "#     plt.show()\n",
    "\n",
    "# # Definir as classes\n",
    "# classes = ['Positive', 'Negative', 'Neutral']\n",
    "\n",
    "# # Plotar a matriz de confusão\n",
    "# plot_confusion_matrix(y_test, y_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e02e7d7-9028-4e40-a048-0b783d828b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Ploting metricas\n",
    "# def plot_metrics(y_true, y_pred, classes):\n",
    "#     precision = precision_score(y_true, y_pred, average=None, labels=classes)\n",
    "#     recall = recall_score(y_true, y_pred, average=None, labels=classes)\n",
    "#     f1 = f1_score(y_true, y_pred, average=None, labels=classes)\n",
    "\n",
    "#     metrics_df = pd.DataFrame({\n",
    "#         'Precision': precision,\n",
    "#         'Recall': recall,\n",
    "#         'F1 Score': f1\n",
    "#     }, index=classes)\n",
    "\n",
    "#     # Transpõe o DataFrame para facilitar a plotagem\n",
    "#     metrics_df = metrics_df.T\n",
    "\n",
    "#     # Definir cores para cada classe\n",
    "#     colors = {'Positive': '#334E68', 'Negative': 'orange', 'Neutral': 'lightgrey'}\n",
    "\n",
    "#     # Plotar o gráfico de barras\n",
    "#     ax = metrics_df.plot(kind='bar', figsize=(10, 6), color=[colors.get(c, 'grey') for c in classes], rot=0)\n",
    "\n",
    "#     # Adicionar os valores acima de cada barra\n",
    "#     for p in ax.patches:\n",
    "#         ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "#                     ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "#     plt.title('Evaluation Metrics by Class')\n",
    "#     plt.ylabel('Valor')\n",
    "#     plt.xlabel('Métrica')\n",
    "    \n",
    "#     # Posiciona a legenda fora da área do gráfico\n",
    "#     plt.legend(title=None, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Plotar métricas\n",
    "# plot_metrics(y_test, y_pred, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5454ed3-598d-4ca0-a97e-ebaefb505ce3",
   "metadata": {},
   "source": [
    "# 4. Neural Network (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaa3bbc7-c953-4fbb-a69b-cb6b8cb332b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|████████████████████████████████████████████████████████████| 440M/440M [00:13<00:00, 31.6MB/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1550ebe9-39b1-459d-b63f-05c3ac0d6238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize and format the input data\n",
    "def tokenize_data(data, max_len=64):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in data['reviews']:\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoding['input_ids'])\n",
    "        attention_masks.append(encoding['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    labels = torch.tensor(data['sentiment'].astype('category').cat.codes.values, dtype=torch.long)\n",
    "\n",
    "    return TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d26a6b7f-487d-4d9d-8d1f-0ef073eebfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\DRT57226\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\DRT57226\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the training and testing data\n",
    "train_dataset = tokenize_data(train_data)\n",
    "test_dataset = tokenize_data(test_data)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for each set\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e199851-c1f4-4788-b759-acbea554c1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DRT57226\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1:   3%|██▎                                                                   | 15/460 [02:50<1:24:15, 11.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[0;32m     19\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     24\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 3\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}'):\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Average training loss: {avg_train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fcebef-cf2a-4ab6-86ea-4d1ab9e0fef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation loop\n",
    "model.eval()\n",
    "val_preds = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "        val_preds.extend(predicted_labels.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Evaluate on validation set\n",
    "print('Validation Report:')\n",
    "print(classification_report(val_labels, val_preds))\n",
    "print(f'Accuracy: {accuracy_score(val_labels, val_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be41e4-ec16-4d53-b135-d153f8a693cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test loop\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc='Testing'):\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "        test_preds.extend(predicted_labels.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "# Evaluate on test set\n",
    "print('Test Report:')\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(f'Accuracy: {accuracy_score(test_labels, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e003b-4717-419a-8749-b9392697caa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapping numerical labels to categorical classes\n",
    "class_mapping = {0: 'Positive', 1: 'Negative', 2: 'Neutral'}\n",
    "\n",
    "# Convert numerical labels to categorical labels\n",
    "test_labels_cat = [class_mapping[label] for label in test_labels]\n",
    "test_preds_cat = [class_mapping[label] for label in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f784b5-8e88-4d20-9755-d13a788610fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Confusion Matrix Function\n",
    "# def plot_confusion_matrix_BERT(y_true, y_pred, classes):\n",
    "#     cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('Real')\n",
    "#     plt.show()\n",
    "\n",
    "# # Define the classes\n",
    "# classes = ['Positive', 'Negative', 'Neutral']\n",
    "\n",
    "# # Plot the confusion matrix\n",
    "# plot_confusion_matrix_BERT(test_labels_cat, test_preds_cat, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63521cdf-cc83-470c-b86a-a672f5c47d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_metrics_BERT(y_true, y_pred, classes):\n",
    "#     unique_labels = sorted(set(y_true + y_pred))\n",
    "#     precision = precision_score(y_true, y_pred, average=None, labels=classes)\n",
    "#     recall = recall_score(y_true, y_pred, average=None, labels=classes)\n",
    "#     f1 = f1_score(y_true, y_pred, average=None, labels=classes)\n",
    "\n",
    "#     metrics_df = pd.DataFrame({\n",
    "#         'Precision': precision,\n",
    "#         'Recall': recall,\n",
    "#         'F1 Score': f1\n",
    "#     }, index=classes)\n",
    "\n",
    "#     # Transpose the DataFrame for easier plotting\n",
    "#     metrics_df = metrics_df.T\n",
    "\n",
    "#     # Define colors for each class\n",
    "#     colors = {'Positive': '#334E68', 'Negative': 'orange', 'Neutral': 'lightgrey'}\n",
    "\n",
    "#     # Plot the bar chart\n",
    "#     ax = metrics_df.plot(kind='bar', figsize=(10, 6), color=[colors.get(c, 'grey') for c in classes], rot=0)\n",
    "\n",
    "#     # Add values above each bar\n",
    "#     for p in ax.patches:\n",
    "#         ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "#                     ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "#     plt.title('Evaluation Metrics by Class')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.xlabel('Metric')\n",
    "    \n",
    "#     # Position the legend outside the plot area\n",
    "#     plt.legend(title=None, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "# # Define the classes\n",
    "# classes = ['Positive', 'Negative', 'Neutral']\n",
    "\n",
    "# # Plot metrics\n",
    "# plot_metrics_BERT(test_labels_cat, test_preds_cat, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dca83-0df1-4445-89f3-edbb1ecd8994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
